# Object Classification with Voice Aid for Visually Impaired

This Android application is designed to assist visually impaired individuals by providing real-time object detection with distance estimation and voice output. It uses the device's camera to automatically detect nearby objects and announces their names and approximate distances without any user interaction.

## ğŸ§  Key Features

- ğŸ“· **Real-time Object Detection** using TensorFlow Lite
- ğŸ”Š **Voice Output** for identified objects
- ğŸ“ **Distance Estimation** to inform users how far the object is
- ğŸ™ï¸ **Voice Commands**: Say "extract text" to switch to text extraction mode, and "stop extracting text" to return to object detection
- ğŸš« **No Tap Required**: App automatically starts detection on launch

## ğŸ› ï¸ Tech Stack

- **Language:** Java
- **Framework:** Android SDK
- **ML Framework:** TensorFlow Lite (TFLite)
- **Voice Output:** Android Text-to-Speech (TTS)
- **Custom Object Labels:** Based on COCO dataset with additional custom class handling
- **Distance Calculation:** Based on camera's field of view and object bounding box

## ğŸš€ How to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/Sksohel2003/object-classification-with-voice-aid-for-visually-impaired.git
Open in Android Studio.

Build and run the app on a physical Android device with camera and microphone access.

âš ï¸ Note: TFLite model file and labels must be placed in the assets folder.

ğŸ“ Folder Structure
perl
Copy
Edit
app/
â”œâ”€â”€ java/
â”‚   â””â”€â”€ ... (MainActivity, DetectorActivity, ObjectDetectorHelper, etc.)
â”œâ”€â”€ res/
â”‚   â””â”€â”€ layout, values, drawable
â”œâ”€â”€ assets/
â”‚   â””â”€â”€ detect.tflite
â”‚   â””â”€â”€ labelmap.txt
ğŸ‘¨â€ğŸ’» Developer
Name: Sohel Shaikh

Email: sohelshaikh123@gmail.com

GitHub: Sksohel2003
